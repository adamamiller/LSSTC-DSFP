{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Construction Zone: Building a Metropolis-Hastings Sampler From Scratch\n",
    "\n",
    "#### Version 0.1\n",
    "\n",
    "-----\n",
    "\n",
    "By AA Miller (Northwestern/Adler Planetarium)\n",
    "\n",
    "27 Aug 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As we just saw, Bayes' Law provides a framework for understanding/inferring model parameters *given* some observations/data:\n",
    "\n",
    "$$P(\\theta\\mid\\mathbf{x}) = \\frac{P(\\mathbf{x}\\mid\\theta)\\;P(\\theta)}{P(\\mathbf{x})},$$\n",
    "\n",
    "where we have used the short-hand notation with $\\theta$ representing the model parameters, and $\\mathbf{x}$ representing the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To redefine some terms,\n",
    "\n",
    "$P(\\mathbf{x}\\mid\\theta)$, the probability of the data given the model parameters, is the *likelihood*, $\\mathcal{L}$.\n",
    "\n",
    "$P(\\theta)$, the probability of the model parameters, is the *prior*.\n",
    "\n",
    "$P(\\mathbf{x})$ the probability of the data, is the *evidence*. (That sounds weird right? More on this in a bit...)\n",
    "\n",
    "Finally, $P(\\theta\\mid\\mathbf{x})$, the probability of the model parameters given the data, is the *posterior*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We typically want to estimate some model parameters, $\\theta$, and thus we need to integrate the posterior, $P(\\theta\\mid\\mathbf{x})$.\n",
    "\n",
    "This is **hard**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In particular, how in the world are we supposed to estimate the *probability of data*?!\n",
    "\n",
    "This is –– capital H –– **Hard**.\n",
    "\n",
    "(We will discuss this on Friday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Fortunately, $P(\\mathbf{x})$ simply serves as a normalization term, and, in many applications, can be ignored. \n",
    "\n",
    "Thus, given that the posterior is $\\propto \\mathcal{L}\\;P(\\theta)$, we can maximize the posterior by maximizing the product of the likelihood and the prior. While this still leaves a complicated integral, there are many tools that can approximate that integral rather efficiently..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "including the Metropolis-Hastings algorithm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
